{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfpUyMj6ftWZ"
      },
      "source": [
        "**Download pre-trained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUtMHJW5MhND",
        "outputId": "678276b1-9245-4ee4-cc88-222abae98152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 110MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision.models import resnet50\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "# Load default pre-trained weights\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "resnet_model = resnet50(weights=weights)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split the data into training, validation and testing while making sure that every category contains the 10 classes"
      ],
      "metadata": {
        "id": "SIyMEhnuhwkk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUsVXnvyOa0c",
        "outputId": "d3dcbe69-e3f4-464f-da3a-d377a3edcc07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm #Shows a nice progress bar during the copying process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NLmGuAwsJqh"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#import shutil\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from torchvision.datasets import ImageFolder\n",
        "#import numpy as np\n",
        "#from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "#source_dir = \"/content/drive/MyDrive/EuroSAT\"     # Folder containing 10 class folders\n",
        "#output_base = \"/content/drive/MyDrive/EuroSAT_splitted\"    # New folder to store train/val/test\n",
        "\n",
        "# Load dataset\n",
        "#dataset = ImageFolder(source_dir)\n",
        "#image_paths = [s[0] for s in dataset.samples]\n",
        "#labels = [s[1] for s in dataset.samples]\n",
        "#class_names = dataset.classes\n",
        "\n",
        "# Split\n",
        "#train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "#    image_paths, labels, test_size=0.3, stratify=labels, random_state=42)\n",
        "\n",
        "#val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "#    temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n",
        "\n",
        "# Copy function\n",
        "#def copy_files(paths, labels, dest):\n",
        "#    for path, label in tqdm(zip(paths, labels), total=len(paths)):\n",
        "#        class_folder = class_names[label]\n",
        "#        target_dir = os.path.join(dest, class_folder)\n",
        "#       os.makedirs(target_dir, exist_ok=True)\n",
        "#       shutil.copy(path, os.path.join(target_dir, os.path.basename(path)))\n",
        "\n",
        "# Copy to Drive\n",
        "#print(\"Copying training data...\")\n",
        "#copy_files(train_paths, train_labels, os.path.join(output_base, \"train\"))\n",
        "\n",
        "#print(\"Copying validation data...\")\n",
        "#copy_files(val_paths, val_labels, os.path.join(output_base, \"val\"))\n",
        "\n",
        "#print(\"Copying test data...\")\n",
        "#copy_files(test_paths, test_labels, os.path.join(output_base, \"test\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load EuroSAT_splitted into loacal colab"
      ],
      "metadata": {
        "id": "GWdfCKijgm8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/EuroSAT_splitted /content/"
      ],
      "metadata": {
        "id": "_nXWl58wdskK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvjr99sIgj7t"
      },
      "source": [
        "**Freeze the base layers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naMNCeiralcl"
      },
      "outputs": [],
      "source": [
        "#resnet_model.requires_grad_(False)\n",
        "for param in resnet_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpn74lTqgveg"
      },
      "source": [
        "**Adding layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNxGHOLLa3fU"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "N_CLASSES = 10\n",
        "#my_model = nn.Sequential(\n",
        "#    resnet_model,\n",
        "#    nn.Linear(1000, N_CLASSES)\n",
        "#)\n",
        "\n",
        "## Instead of adding a new layer after resnet_model, replace its .fc:\n",
        "resnet_model.fc = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(resnet_model.fc.in_features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.3),\n",
        "    nn.Linear(256, 10)\n",
        ")\n",
        "my_model = resnet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3KW875NhAFp"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Loss function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCPTkM50bQcH"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC8OzI09hFxD"
      },
      "source": [
        "**Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBdeiOdDei57"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "optimizer = Adam(my_model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qALkUBJ9JUVw"
      },
      "source": [
        "**Model** **compilation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7kNXi0pJSBF"
      },
      "outputs": [],
      "source": [
        "my_model = torch.compile(my_model.to(device), backend=\"eager\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPzed70ImF_A"
      },
      "source": [
        "**Pre_processing transforms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2g2KFQxfPoJ"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms.v2 as transforms\n",
        "pre_trans = weights.transforms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woyWkVK3_n4p"
      },
      "source": [
        "**Custom Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh9kyETJM6Lx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "DATA_LABELS = [\"AnnualCrop\", \"Forest\", \"HerbaceousVegetation\", \"Highway\", \"Industrial\",\n",
        "               \"Pasture\", \"PermanentCrop\", \"Residential\", \"River\", \"SeaLake\"]\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        for l_idx, label in enumerate(DATA_LABELS):\n",
        "            paths = glob.glob(os.path.join(data_dir, label, '*.jpg'))\n",
        "            for path in paths:\n",
        "                self.image_paths.append(path)\n",
        "                self.labels.append(l_idx)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(self.labels[idx]).long()\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data** **augmentation**"
      ],
      "metadata": {
        "id": "g8N6w_fslSqC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHT_nYghPxH9"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.v2 import (\n",
        "    Compose, RandomResizedCrop, ColorJitter, RandomHorizontalFlip, RandomRotation, ToTensor, Normalize\n",
        ")\n",
        "\n",
        "random_trans = Compose([\n",
        "    RandomResizedCrop(64, scale=(0.7, 1.0)),\n",
        "    ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.02),\n",
        "    RandomHorizontalFlip(),\n",
        "    RandomRotation(20),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406],\n",
        "              std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "8oOxHwytlbZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxpP12_h7BYD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from random import shuffle\n",
        "\n",
        "n = 32\n",
        "\n",
        "#train_path = \"/content/drive/MyDrive/EuroSAT_splitted/train\"\n",
        "train_path = \"/content/EuroSAT_splitted/train\"\n",
        "train_data = MyDataset(train_path, transform = random_trans)\n",
        "train_loader = DataLoader(train_data, batch_size = n, shuffle = True)\n",
        "train_N = len(train_loader.dataset)\n",
        "\n",
        "#valid_path = \"/content/drive/MyDrive/EuroSAT_splitted/val\"\n",
        "valid_path = \"/content/EuroSAT_splitted/val\"\n",
        "valid_data = MyDataset(valid_path, transform = random_trans)\n",
        "valid_loader = DataLoader(valid_data, batch_size = n)\n",
        "valid_N = len(valid_loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf7y069BOGr1"
      },
      "source": [
        "**Train function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02SzNgQAOJoL"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, train_N, random_trans, optimizer, loss_function):\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        output = model(x.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss = loss_function(output, y.to(device))\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss += batch_loss.item()\n",
        "        accuracy += get_batch_accuracy(output, y.to(device), train_N)\n",
        "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0KDPEVJOh1B"
      },
      "source": [
        "**Validate function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i72QiBRWOlMj"
      },
      "outputs": [],
      "source": [
        "def validate(model, valid_loader, valid_N, loss_function):\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in valid_loader:\n",
        "            output = model(x.to(device))\n",
        "\n",
        "            loss += loss_function(output, y.to(device)).item()\n",
        "            accuracy += get_batch_accuracy(output, y.to(device), valid_N)\n",
        "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0hBABidUYh4"
      },
      "source": [
        "**Accuracy function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQLI9TF4UggV"
      },
      "outputs": [],
      "source": [
        "def get_batch_accuracy(output, y, N):\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    correct = pred.eq(y.view_as(pred)).sum().item()\n",
        "    return correct / N"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training loop**"
      ],
      "metadata": {
        "id": "7qCYvoEplo0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLAIRZOLNgY3",
        "outputId": "9d158a3d-8853-4216-d53a-42756e25b103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Train - Loss: 721.6732 Accuracy: 0.5978\n",
            "Valid - Loss: 97.3316 Accuracy: 0.7496\n",
            "Epoch: 1\n",
            "Train - Loss: 607.0313 Accuracy: 0.6531\n",
            "Valid - Loss: 99.7766 Accuracy: 0.7451\n",
            "Epoch: 2\n",
            "Train - Loss: 579.3428 Accuracy: 0.6744\n",
            "Valid - Loss: 91.6413 Accuracy: 0.7646\n",
            "Epoch: 3\n",
            "Train - Loss: 578.5622 Accuracy: 0.6710\n",
            "Valid - Loss: 87.1741 Accuracy: 0.7745\n",
            "Epoch: 4\n",
            "Train - Loss: 572.3662 Accuracy: 0.6738\n",
            "Valid - Loss: 89.0651 Accuracy: 0.7686\n",
            "Epoch: 5\n",
            "Train - Loss: 565.6212 Accuracy: 0.6830\n",
            "Valid - Loss: 90.3636 Accuracy: 0.7609\n",
            "Epoch: 6\n",
            "Train - Loss: 556.6621 Accuracy: 0.6818\n",
            "Valid - Loss: 88.4901 Accuracy: 0.7792\n",
            "Epoch: 7\n",
            "Train - Loss: 556.3090 Accuracy: 0.6811\n",
            "Valid - Loss: 81.4402 Accuracy: 0.7957\n",
            "Epoch: 8\n",
            "Train - Loss: 551.7430 Accuracy: 0.6841\n",
            "Valid - Loss: 88.0160 Accuracy: 0.7839\n",
            "Epoch: 9\n",
            "Train - Loss: 550.3698 Accuracy: 0.6853\n",
            "Valid - Loss: 90.2577 Accuracy: 0.7604\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    train(my_model, train_loader, train_N, random_trans, optimizer, loss_function)\n",
        "    validate(my_model, valid_loader, valid_N, loss_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDF9AWFHDqBj"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fpmVqdA5Kjj"
      },
      "source": [
        "**Unfreeze the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcQR8z2lNsJ0"
      },
      "outputs": [],
      "source": [
        "resnet_model.requires_grad_(True)\n",
        "optimizer = Adam(my_model.parameters(), lr=.00010)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data augmentation for the final training** (Resnet expects 224*224 images)"
      ],
      "metadata": {
        "id": "DSKj_-rnlzcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0NQWpe3I4J5",
        "outputId": "7c89ce74-1ce5-4bde-93a8-457743caab30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "random_trans224 = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.Resize((224, 224)),  # <-- full size for ResNet\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "nGt1ICGqmFdh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E_BNTNAI2P-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from random import shuffle\n",
        "\n",
        "n = 32\n",
        "\n",
        "#train_path = \"/content/drive/MyDrive/EuroSAT_splitted/train\"\n",
        "train_path = \"/content/EuroSAT_splitted/train\"\n",
        "train_data = MyDataset(train_path, transform = random_trans224)\n",
        "train_loader = DataLoader(train_data, batch_size = n, shuffle = True)\n",
        "train_N = len(train_loader.dataset)\n",
        "\n",
        "#valid_path = \"/content/drive/MyDrive/EuroSAT_splitted/val\"\n",
        "valid_path = \"/content/EuroSAT_splitted/val\"\n",
        "valid_data = MyDataset(valid_path, transform = random_trans224)\n",
        "valid_loader = DataLoader(valid_data, batch_size = n)\n",
        "valid_N = len(valid_loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training loop**"
      ],
      "metadata": {
        "id": "TxCsnLd4mToN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2NTOdps63Pr",
        "outputId": "94f41ef3-fed7-4b43-dcaf-aee766639da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Train - Loss: 157.0211 Accuracy: 0.9119\n",
            "Valid - Loss: 12.9785 Accuracy: 0.9615\n",
            "Epoch: 1\n",
            "Train - Loss: 73.6918 Accuracy: 0.9583\n",
            "Valid - Loss: 8.9507 Accuracy: 0.9778\n"
          ]
        }
      ],
      "source": [
        "epochs = 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    train(my_model, train_loader, train_N, random_trans224, optimizer, loss_function)\n",
        "    validate(my_model, valid_loader, valid_N, loss_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the model**"
      ],
      "metadata": {
        "id": "rZqQyXqCma9z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de82bnrvMirC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(\"/content/drive/MyDrive/checkpoints\", exist_ok=True)\n",
        "\n",
        "# Now save\n",
        "torch.save(my_model.state_dict(), f\"/content/drive/MyDrive/checkpoints/model_epoch{epoch}.pth\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}