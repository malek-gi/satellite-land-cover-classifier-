# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l26DoRfkZGE55WI_k1ssakArZbzC2IBX

**Download pre-trained model**
"""

import torch
from torchvision.models import resnet50
from torchvision.models import ResNet50_Weights

# Load default pre-trained weights
weights = ResNet50_Weights.DEFAULT
resnet_model = resnet50(weights=weights)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.cuda.is_available()

"""split the data into training, validation and testing while making sure that every category contains the 10 classes"""

!pip install tqdm #Shows a nice progress bar during the copying process

#import os
#import shutil
#from sklearn.model_selection import train_test_split
#from torchvision.datasets import ImageFolder
#import numpy as np
#from tqdm import tqdm

# Paths
#source_dir = "/content/drive/MyDrive/EuroSAT"     # Folder containing 10 class folders
#output_base = "/content/drive/MyDrive/EuroSAT_splitted"    # New folder to store train/val/test

# Load dataset
#dataset = ImageFolder(source_dir)
#image_paths = [s[0] for s in dataset.samples]
#labels = [s[1] for s in dataset.samples]
#class_names = dataset.classes

# Split
#train_paths, temp_paths, train_labels, temp_labels = train_test_split(
#    image_paths, labels, test_size=0.3, stratify=labels, random_state=42)

#val_paths, test_paths, val_labels, test_labels = train_test_split(
#    temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)

# Copy function
#def copy_files(paths, labels, dest):
#    for path, label in tqdm(zip(paths, labels), total=len(paths)):
#        class_folder = class_names[label]
#        target_dir = os.path.join(dest, class_folder)
#       os.makedirs(target_dir, exist_ok=True)
#       shutil.copy(path, os.path.join(target_dir, os.path.basename(path)))

# Copy to Drive
#print("Copying training data...")
#copy_files(train_paths, train_labels, os.path.join(output_base, "train"))

#print("Copying validation data...")
#copy_files(val_paths, val_labels, os.path.join(output_base, "val"))

#print("Copying test data...")
#copy_files(test_paths, test_labels, os.path.join(output_base, "test"))

"""load EuroSAT_splitted into loacal colab"""

!cp -r /content/drive/MyDrive/EuroSAT_splitted /content/

"""**Freeze the base layers**"""

#resnet_model.requires_grad_(False)
for param in resnet_model.parameters():
    param.requires_grad = False

"""**Adding layer**"""

import torch.nn as nn
N_CLASSES = 10
#my_model = nn.Sequential(
#    resnet_model,
#    nn.Linear(1000, N_CLASSES)
#)

## Instead of adding a new layer after resnet_model, replace its .fc:
resnet_model.fc = nn.Sequential(
    nn.Dropout(p=0.5),
    nn.Linear(resnet_model.fc.in_features, 256),
    nn.ReLU(),
    nn.Dropout(p=0.3),
    nn.Linear(256, 10)
)
my_model = resnet_model

"""








**Loss function**"""

loss_function = nn.CrossEntropyLoss()

"""**Optimizer**"""

from torch.optim import Adam
optimizer = Adam(my_model.parameters())

"""**Model** **compilation**"""

my_model = torch.compile(my_model.to(device), backend="eager")

"""**Pre_processing transforms**"""

import torchvision.transforms.v2 as transforms
pre_trans = weights.transforms()

"""**Custom Dataset**"""

import os
import glob
import torch
from torch.utils.data import Dataset
from PIL import Image

DATA_LABELS = ["AnnualCrop", "Forest", "HerbaceousVegetation", "Highway", "Industrial",
               "Pasture", "PermanentCrop", "Residential", "River", "SeaLake"]

class MyDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.image_paths = []
        self.labels = []
        self.transform = transform

        for l_idx, label in enumerate(DATA_LABELS):
            paths = glob.glob(os.path.join(data_dir, label, '*.jpg'))
            for path in paths:
                self.image_paths.append(path)
                self.labels.append(l_idx)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("RGB")
        if self.transform:
            image = self.transform(image)
        label = torch.tensor(self.labels[idx]).long()
        return image, label

    def __len__(self):
        return len(self.image_paths)

"""**Data** **augmentation**"""

from torchvision.transforms.v2 import (
    Compose, RandomResizedCrop, ColorJitter, RandomHorizontalFlip, RandomRotation, ToTensor, Normalize
)

random_trans = Compose([
    RandomResizedCrop(64, scale=(0.7, 1.0)),
    ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.02),
    RandomHorizontalFlip(),
    RandomRotation(20),
    ToTensor(),
    Normalize(mean=[0.485, 0.456, 0.406],
              std=[0.229, 0.224, 0.225])
])

"""**Preprocessing**"""

import torch
import os
from torch.utils.data import DataLoader
from random import shuffle

n = 32

#train_path = "/content/drive/MyDrive/EuroSAT_splitted/train"
train_path = "/content/EuroSAT_splitted/train"
train_data = MyDataset(train_path, transform = random_trans)
train_loader = DataLoader(train_data, batch_size = n, shuffle = True)
train_N = len(train_loader.dataset)

#valid_path = "/content/drive/MyDrive/EuroSAT_splitted/val"
valid_path = "/content/EuroSAT_splitted/val"
valid_data = MyDataset(valid_path, transform = random_trans)
valid_loader = DataLoader(valid_data, batch_size = n)
valid_N = len(valid_loader.dataset)

"""**Train function**"""

def train(model, train_loader, train_N, random_trans, optimizer, loss_function):
    loss = 0
    accuracy = 0

    model.train()
    for x, y in train_loader:
        output = model(x.to(device))
        optimizer.zero_grad()
        batch_loss = loss_function(output, y.to(device))
        batch_loss.backward()
        optimizer.step()

        loss += batch_loss.item()
        accuracy += get_batch_accuracy(output, y.to(device), train_N)
    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))

"""**Validate function**"""

def validate(model, valid_loader, valid_N, loss_function):
    loss = 0
    accuracy = 0

    model.eval()
    with torch.no_grad():
        for x, y in valid_loader:
            output = model(x.to(device))

            loss += loss_function(output, y.to(device)).item()
            accuracy += get_batch_accuracy(output, y.to(device), valid_N)
    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))

"""**Accuracy function**"""

def get_batch_accuracy(output, y, N):
    pred = output.argmax(dim=1, keepdim=True)
    correct = pred.eq(y.view_as(pred)).sum().item()
    return correct / N

"""**Training loop**"""

epochs = 10

for epoch in range(epochs):
    print('Epoch: {}'.format(epoch))
    train(my_model, train_loader, train_N, random_trans, optimizer, loss_function)
    validate(my_model, valid_loader, valid_N, loss_function)

"""**Unfreeze the model**"""

resnet_model.requires_grad_(True)
optimizer = Adam(my_model.parameters(), lr=.00010)

"""**Data augmentation for the final training** (Resnet expects 224*224 images)"""

random_trans224 = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.Resize((224, 224)),  # <-- full size for ResNet
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

"""**Preprocessing**"""

import torch
import os
from torch.utils.data import DataLoader
from random import shuffle

n = 32

#train_path = "/content/drive/MyDrive/EuroSAT_splitted/train"
train_path = "/content/EuroSAT_splitted/train"
train_data = MyDataset(train_path, transform = random_trans224)
train_loader = DataLoader(train_data, batch_size = n, shuffle = True)
train_N = len(train_loader.dataset)

#valid_path = "/content/drive/MyDrive/EuroSAT_splitted/val"
valid_path = "/content/EuroSAT_splitted/val"
valid_data = MyDataset(valid_path, transform = random_trans224)
valid_loader = DataLoader(valid_data, batch_size = n)
valid_N = len(valid_loader.dataset)

"""**Training loop**"""

epochs = 2

for epoch in range(epochs):
    print('Epoch: {}'.format(epoch))
    train(my_model, train_loader, train_N, random_trans224, optimizer, loss_function)
    validate(my_model, valid_loader, valid_N, loss_function)

"""**Save the model**"""

import os

# Ensure the directory exists
os.makedirs("/content/drive/MyDrive/checkpoints", exist_ok=True)

# Now save
torch.save(my_model.state_dict(), f"/content/drive/MyDrive/checkpoints/model_epoch{epoch}.pth")